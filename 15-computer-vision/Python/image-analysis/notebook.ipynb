{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from array import array\n",
    "from PIL import Image, ImageDraw\n",
    "import sys\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# import namespaces\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "cog_endpoint = os.getenv('COG_SERVICE_ENDPOINT')\n",
    "cog_key = os.getenv('COG_SERVICE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = 'images/building.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = CognitiveServicesCredentials(cog_key) \n",
    "cv_client = ComputerVisionClient(cog_endpoint, credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnalyzeImage(image_file):\n",
    "    print('Analyzing', image_file)\n",
    "\n",
    "    # Specify features to be retrieved\n",
    "    features = [VisualFeatureTypes.description,\n",
    "                VisualFeatureTypes.tags,\n",
    "                VisualFeatureTypes.categories,\n",
    "                VisualFeatureTypes.brands,\n",
    "                VisualFeatureTypes.objects,\n",
    "                VisualFeatureTypes.adult]\n",
    "    \n",
    "    \n",
    "    # Get image analysis\n",
    "    with open(image_file, mode=\"rb\") as image_data:\n",
    "        analysis = cv_client.analyze_image_in_stream(image_data , features)\n",
    "\n",
    "    return analysis\n",
    "\n",
    "    # # Get image description\n",
    "    # for caption in analysis.description.captions:\n",
    "    #     print(\"Description: '{}' (confidence: {:.2f}%)\".format(caption.text, caption.confidence * 100))\n",
    "\n",
    "    # # Get image tags\n",
    "    # if (len(analysis.tags) > 0):\n",
    "    #     print(\"Tags: \")\n",
    "    #     for tag in analysis.tags:\n",
    "    #         print(\" -'{}' (confidence: {:.2f}%)\".format(tag.name, tag.confidence * 100))\n",
    "\n",
    "\n",
    "    # # Get image categories\n",
    "    # if (len(analysis.categories) > 0):\n",
    "    #     print(\"Categories:\")\n",
    "    #     landmarks = []\n",
    "    #     for category in analysis.categories:\n",
    "    #         # Print the category\n",
    "    #         print(\" -'{}' (confidence: {:.2f}%)\".format(category.name, category.score * 100))\n",
    "    #         if category.detail:\n",
    "    #             # Get landmarks in this category\n",
    "    #             if category.detail.landmarks:\n",
    "    #                 for landmark in category.detail.landmarks:\n",
    "    #                     if landmark not in landmarks:\n",
    "    #                         landmarks.append(landmark)\n",
    "\n",
    "    #     # If there were landmarks, list them\n",
    "    #     if len(landmarks) > 0:\n",
    "    #         print(\"Landmarks:\")\n",
    "    #         for landmark in landmarks:\n",
    "    #             print(\" -'{}' (confidence: {:.2f}%)\".format(landmark.name, landmark.confidence * 100))\n",
    "\n",
    "\n",
    "\n",
    "    # # Get brands in the image\n",
    "    # if (len(analysis.brands) > 0):\n",
    "    #     print(\"Brands: \")\n",
    "    #     for brand in analysis.brands:\n",
    "    #         print(\" -'{}' (confidence: {:.2f}%)\".format(brand.name, brand.confidence * 100))\n",
    "\n",
    "\n",
    "    # # Get objects in the image\n",
    "    # if len(analysis.objects) > 0:\n",
    "    #     print(\"Objects in image:\")\n",
    "\n",
    "    #     # Prepare image for drawing\n",
    "    #     fig = plt.figure(figsize=(8, 8))\n",
    "    #     plt.axis('off')\n",
    "    #     image = Image.open(image_file)\n",
    "    #     draw = ImageDraw.Draw(image)\n",
    "    #     color = 'cyan'\n",
    "    #     for detected_object in analysis.objects:\n",
    "    #         # Print object name\n",
    "    #         print(\" -{} (confidence: {:.2f}%)\".format(detected_object.object_property, detected_object.confidence * 100))\n",
    "            \n",
    "    #         # Draw object bounding box\n",
    "    #         r = detected_object.rectangle\n",
    "    #         bounding_box = ((r.x, r.y), (r.x + r.w, r.y + r.h))\n",
    "    #         draw.rectangle(bounding_box, outline=color, width=3)\n",
    "    #         plt.annotate(detected_object.object_property,(r.x, r.y), backgroundcolor=color)\n",
    "    #     # Save annotated image\n",
    "    #     plt.imshow(image)\n",
    "    #     outputfile = 'objects.jpg'\n",
    "    #     fig.savefig(outputfile)\n",
    "    #     print('  Results saved in', outputfile)\n",
    "\n",
    "\n",
    "    # # Get moderation ratings\n",
    "    # ratings = 'Ratings:\\n -Adult: {}\\n -Racy: {}\\n -Gore: {}'.format(analysis.adult.is_adult_content,\n",
    "    #                                                                     analysis.adult.is_racy_content,\n",
    "    #                                                                     analysis.adult.is_gory_content)\n",
    "    # print(ratings)\n",
    "\n",
    "def GetThumbnail(image_file):\n",
    "    print('Generating thumbnail')\n",
    "\n",
    "    # Generate a thumbnail\n",
    "    with open(image_file, mode=\"rb\") as image_data:\n",
    "        # Get thumbnail data\n",
    "        thumbnail_stream = cv_client.generate_thumbnail_in_stream(100, 100, image_data, True)\n",
    "\n",
    "    # Save thumbnail image\n",
    "    thumbnail_file_name = 'thumbnail.png'\n",
    "    with open(thumbnail_file_name, \"wb\") as thumbnail_file:\n",
    "        for chunk in thumbnail_stream:\n",
    "            thumbnail_file.write(chunk)\n",
    "\n",
    "    print('Thumbnail saved in.', thumbnail_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing images/building.jpg\n"
     ]
    }
   ],
   "source": [
    "result = AnalyzeImage(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_properties': {},\n",
       " 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category at 0x1f66246acb0>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.Category at 0x1f66246ac50>],\n",
       " 'adult': <azure.cognitiveservices.vision.computervision.models._models_py3.AdultInfo at 0x1f651d1ba00>,\n",
       " 'color': None,\n",
       " 'image_type': None,\n",
       " 'tags': [<azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a6b0>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a5c0>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a5f0>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a620>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a740>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a7d0>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a890>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a800>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a710>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a590>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246a500>,\n",
       "  <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag at 0x1f66246ae60>],\n",
       " 'description': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageDescriptionDetails at 0x1f66246ab60>,\n",
       " 'faces': None,\n",
       " 'objects': [<azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x1f662468670>],\n",
       " 'brands': [],\n",
       " 'request_id': '9dd7462c-a81e-42ad-9989-451c036ad8d8',\n",
       " 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata at 0x1f66246abf0>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_properties': {}, 'x': 183, 'y': 43, 'w': 535, 'h': 369}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(result.objects[0].rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'outdoor', 'confidence': 0.9998234510421753, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'road', 'confidence': 0.9998223781585693, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'building', 'confidence': 0.9992225170135498, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'street', 'confidence': 0.9953342080116272, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'land vehicle', 'confidence': 0.9367624521255493, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'way', 'confidence': 0.9366739988327026, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'dog', 'confidence': 0.9355420470237732, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'vehicle', 'confidence': 0.9255756139755249, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'car', 'confidence': 0.9137619733810425, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'sidewalk', 'confidence': 0.8751448392868042, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'city', 'confidence': 0.8610316514968872, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'wheel', 'confidence': 0.6986751556396484, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'people', 'confidence': 0.6572133302688599, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'yellow', 'confidence': 0.6493577361106873, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'carnivore', 'confidence': 0.6382932066917419, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'taxi', 'confidence': 0.6063252687454224, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'busy', 'confidence': 0.30321383476257324, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'curb', 'confidence': 0.07645836472511292, 'hint': None}\n"
     ]
    }
   ],
   "source": [
    "for tag in result.tags:\n",
    "    print(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'outdoor_', 'score': 0.00390625, 'detail': <azure.cognitiveservices.vision.computervision.models._models_py3.CategoryDetail object at 0x0000025BDC53B160>}\n",
      "{'additional_properties': {}, 'name': 'outdoor_road', 'score': 0.55859375, 'detail': <azure.cognitiveservices.vision.computervision.models._models_py3.CategoryDetail object at 0x0000025BDC53B9A0>}\n"
     ]
    }
   ],
   "source": [
    "for category in result.categories:\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'text': 'a person walking a dog on a sidewalk', 'confidence': 0.4695983827114105}\n"
     ]
    }
   ],
   "source": [
    "for caption in result.description.captions:\n",
    "    print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_properties': {},\n",
       " 'is_adult_content': False,\n",
       " 'is_racy_content': False,\n",
       " 'is_gory_content': False,\n",
       " 'adult_score': 0.00780514208599925,\n",
       " 'racy_score': 0.013629540801048279,\n",
       " 'gore_score': 0.010736235417425632}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(result.adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'rectangle': <azure.cognitiveservices.vision.computervision.models._models_py3.BoundingRect object at 0x0000025BCBE70100>, 'object_property': 'car', 'confidence': 0.724, 'parent': <azure.cognitiveservices.vision.computervision.models._models_py3.ObjectHierarchy object at 0x0000025BCBE72950>}\n",
      "{'additional_properties': {}, 'rectangle': <azure.cognitiveservices.vision.computervision.models._models_py3.BoundingRect object at 0x0000025BCBE71E10>, 'object_property': 'taxi', 'confidence': 0.77, 'parent': <azure.cognitiveservices.vision.computervision.models._models_py3.ObjectHierarchy object at 0x0000025BCBE726E0>}\n",
      "{'additional_properties': {}, 'rectangle': <azure.cognitiveservices.vision.computervision.models._models_py3.BoundingRect object at 0x0000025BCBE723B0>, 'object_property': 'person', 'confidence': 0.781, 'parent': None}\n",
      "{'additional_properties': {}, 'rectangle': <azure.cognitiveservices.vision.computervision.models._models_py3.BoundingRect object at 0x0000025BCBE72500>, 'object_property': 'dog', 'confidence': 0.544, 'parent': <azure.cognitiveservices.vision.computervision.models._models_py3.ObjectHierarchy object at 0x0000025BCBD33FD0>}\n"
     ]
    }
   ],
   "source": [
    "for object in result.objects:\n",
    "    print(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'x': 0, 'y': 212, 'w': 282, 'h': 149}\n"
     ]
    }
   ],
   "source": [
    "print(result.objects[0].rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
